# Whisper AI Configuration

# Model settings
model:
  name: "base"  # Choose between "tiny", "base", "small", "medium", "large"
  language: "auto"  # Set to specific language code or "auto" for automatic detection

# Audio processing
audio:
  input_file: "input.wav"
  output_file: "output"
  output_format: "txt"
  chunk_size: 300  # Seconds

# Performance settings
performance:
  device: "cuda"  # Use "cuda" for GPU or "cpu" for CPU
  num_workers: 2  # Number of worker threads for parallel processing

# Whisper settings
whisper:
  sample_rate: 16000  # Audio sample rate
  temperature: 0
  compression_ratio_threshold: 2.4
  logprob_threshold: -1.0
  no_speech_threshold: 0.6
  fp16: true  # Will be overridden based on CUDA availability

# Diarization settings
diarization:
  enabled: false
  model: "pyannote/speaker-diarization@2.1"
  auth_token: "YOUR_HF_AUTH_TOKEN"
  num_speakers: 2
  min_duration_off: 0.5
  min_cluster_size: 15

# Translation settings
translation:
  enabled: false
  target_language: "en"

# Preprocessing settings
preprocess:
  enabled: false
  output_file: "preprocessed_audio.wav"
  noise_reduction: true
  normalize: true

# Logging
logging:
  level: "INFO"
  file: "whisper_transcription.log"